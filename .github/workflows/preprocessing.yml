name: Automated Preprocessing Pipeline

on:
  push:
    branches: [ main, master ]
    paths:
      - 'preprocessing/**'
      - 'dataset_raw/**'
      - '.github/workflows/preprocessing.yml'
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:

jobs:
  preprocessing:
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4
    
    - name: ğŸ Set up Python 3.12
      uses: actions/setup-python@v5
      with:
        python-version: '3.12.7'
        cache: 'pip'
    
    - name: ğŸ“¦ Install Dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        pip install pandas==2.2.0
        pip install numpy==1.26.3
        pip install scikit-learn==1.4.0
        pip install scipy==1.12.0
    
    - name: ğŸ” Verify Installation
      run: |
        python -c "import pandas; print(f'âœ… pandas {pandas.__version__}')"
        python -c "import numpy; print(f'âœ… numpy {numpy.__version__}')"
        python -c "import sklearn; print(f'âœ… scikit-learn {sklearn.__version__}')"
        python -c "import scipy; print(f'âœ… scipy {scipy.__version__}')"
    
    - name: ğŸ” Verify Files
      run: |
        echo "Checking project structure..."
        ls -la
        echo ""
        echo "Checking dataset_raw..."
        ls -la dataset_raw/
        echo ""
        echo "Checking preprocessing..."
        ls -la preprocessing/
    
    - name: ğŸ”§ Run Preprocessing
      run: |
        cd preprocessing
        python automate_Amirullah.py
    
    - name: âœ… Verify Preprocessed Data
      run: |
        echo "Checking output files..."
        ls -la preprocessing/dataset_preprocessing/
        echo ""
        
        echo "Verifying train_processed.csv..."
        python -c "import pandas as pd; df=pd.read_csv('preprocessing/dataset_preprocessing/train_processed.csv'); print(f'âœ… Train: {df.shape}')"
        
        echo "Verifying test_processed.csv..."
        python -c "import pandas as pd; df=pd.read_csv('preprocessing/dataset_preprocessing/test_processed.csv'); print(f'âœ… Test: {df.shape}')"
        
        echo "Verifying scaler.pkl..."
        python -c "import pickle; import os; assert os.path.exists('preprocessing/dataset_preprocessing/scaler.pkl'); print('âœ… Scaler exists')"
    
    - name: ğŸ“Š Generate Summary
      run: |
        {
          echo "## ğŸ“Š Preprocessing Summary"
          echo ""
          echo "âœ… **Status:** Preprocessing completed successfully!"
          echo ""
          python -c "
        import pandas as pd
        train = pd.read_csv('preprocessing/dataset_preprocessing/train_processed.csv')
        test = pd.read_csv('preprocessing/dataset_preprocessing/test_processed.csv')
        
        print('**Dataset Shape:**')
        print(f'- Training: {train.shape}')
        print(f'- Test: {test.shape}')
        print(f'- Total Features: {train.shape[1] - 1}')
        "
        } >> $GITHUB_STEP_SUMMARY
    
    - name: ğŸ“¤ Upload Preprocessed Data as Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: preprocessed-dataset
        path: preprocessing/dataset_preprocessing/
        retention-days: 30
        compression-level: 6
    
    - name: ğŸ‰ Success Notification
      if: success()
      run: |
        echo ""
        echo "========================================="
        echo "âœ…âœ…âœ… PREPROCESSING COMPLETED! âœ…âœ…âœ…"
        echo "========================================="
        echo ""
        echo "ğŸ“Š Preprocessed data uploaded as artifacts"
        echo "ğŸ“¥ Download from Actions â†’ Artifacts section"
        echo ""
    
    - name: âŒ Failure Notification
      if: failure()
      run: |
        echo ""
        echo "========================================="
        echo "âŒ PREPROCESSING FAILED"
        echo "========================================="
        echo ""
        echo "Check logs above for error details"
        echo ""
