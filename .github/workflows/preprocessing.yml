name: Automated Preprocessing Pipeline

on:
  push:
    branches: [ main, master ]
    paths:
      - 'preprocessing/**'
      - 'dataset_raw/**'
      - '.github/workflows/preprocessing.yml'
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:

jobs:
  preprocessing:
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v3
    
    - name: ğŸ Set up Python 3.12
      uses: actions/setup-python@v4
      with:
        python-version: '3.12.7'
    
    - name: ğŸ“¦ Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas==2.0.3
        pip install numpy==1.25.2
        pip install scikit-learn==1.3.0
        pip install scipy==1.11.2
    
    - name: ğŸ” Verify Files
      run: |
        echo "Checking project structure..."
        ls -la
        echo "Checking dataset_raw..."
        ls -la dataset_raw/
        echo "Checking preprocessing..."
        ls -la preprocessing/
    
    - name: ğŸ”§ Run Preprocessing
      run: |
        cd preprocessing
        python automate_Amirullah.py
    
    - name: âœ… Verify Preprocessed Data
      run: |
        echo "Checking output files..."
        ls -la preprocessing/dataset_preprocessing/
        
        echo "Verifying train_processed.csv..."
        python -c "import pandas as pd; df=pd.read_csv('preprocessing/dataset_preprocessing/train_processed.csv'); print(f'âœ… Train: {df.shape}')"
        
        echo "Verifying test_processed.csv..."
        python -c "import pandas as pd; df=pd.read_csv('preprocessing/dataset_preprocessing/test_processed.csv'); print(f'âœ… Test: {df.shape}')"
        
        echo "Verifying scaler.pkl..."
        python -c "import pickle; import os; assert os.path.exists('preprocessing/dataset_preprocessing/scaler.pkl'); print('âœ… Scaler exists')"
    
    - name: ğŸ“Š Generate Summary
      run: |
        echo "## ğŸ“Š Preprocessing Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "âœ… **Status:** Preprocessing completed successfully!" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        python -c "
        import pandas as pd
        train = pd.read_csv('preprocessing/dataset_preprocessing/train_processed.csv')
        test = pd.read_csv('preprocessing/dataset_preprocessing/test_processed.csv')
        
        print('**Dataset Shape:**')
        print(f'- Training: {train.shape}')
        print(f'- Test: {test.shape}')
        print(f'- Total Features: {train.shape[1] - 1}')
        " >> $GITHUB_STEP_SUMMARY
    
    - name: ğŸ“¤ Upload Preprocessed Data as Artifacts
      uses: actions/upload-artifact@v3
      with:
        name: preprocessed-dataset
        path: preprocessing/dataset_preprocessing/
        retention-days: 30
    
    - name: ğŸ‰ Success Notification
      if: success()
      run: |
        echo "âœ…âœ…âœ… PREPROCESSING PIPELINE COMPLETED SUCCESSFULLY! âœ…âœ…âœ…"
    
    - name: âŒ Failure Notification
      if: failure()
      run: |
        echo "âŒ Preprocessing pipeline failed. Check logs above for details."
